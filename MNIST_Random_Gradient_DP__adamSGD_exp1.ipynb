{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/STANLEii/STANLEii/blob/main/MNIST_Random_Gradient_DP__adamSGD_exp1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import itertools\n",
        "import torch\n",
        "\n",
        "def safe_apply(appliable, func, **param):\n",
        "    return functools.partial(func, **param) if appliable(**param) else (lambda _: _)\n",
        "\n",
        "def grad_clip(grad, norm_bound):\n",
        "    if grad.norm() <= norm_bound:\n",
        "        return grad\n",
        "    return grad.div_(grad.norm()).mul_(norm_bound)\n",
        "\n",
        "def grad_add_noise(grad, noise_scale):\n",
        "    return grad.add_(noise_scale, torch.randn(list(grad.size()), device=grad.device))\n",
        "\n",
        "clip_generator = functools.partial(safe_apply,\n",
        "    appliable=(lambda norm_bound: norm_bound != 0),\n",
        "    func=grad_clip,\n",
        ")\n",
        "\n",
        "add_noise_generator = functools.partial(safe_apply,\n",
        "    appliable=(lambda noise_scale: noise_scale != 0),\n",
        "    func=grad_add_noise,\n",
        ")\n",
        "\n",
        "def combine_iterators(*iterators):\n",
        "    end = False\n",
        "    # Type Casting\n",
        "    iterators = [*map(iter, iterators)]\n",
        "    while not end:\n",
        "        end = True\n",
        "        nexts = ()\n",
        "        for iterator in iterators:\n",
        "            try:\n",
        "                nexts = nexts + tuple([iterator.__next__()])\n",
        "                end = False\n",
        "            except StopIteration:\n",
        "                nexts = nexts + tuple([None])\n",
        "        if not end:\n",
        "            yield nexts"
      ],
      "metadata": {
        "id": "TfYZ5tXQBm6B"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "#from .._util import clip_generator, add_noise_generator\n",
        "\n",
        "class DPAdam(Optimizer):\n",
        "    r\"\"\"Implements Adam algorithm.\n",
        "\n",
        "    It has been proposed in `Adam: A Method for Stochastic Optimization`_.\n",
        "\n",
        "    Arguments:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float, optional): learning rate (default: 1e-3)\n",
        "        betas (Tuple[float, float], optional): coefficients used for computing\n",
        "            running averages of gradient and its square (default: (0.9, 0.999))\n",
        "        eps (float, optional): term added to the denominator to improve\n",
        "            numerical stability (default: 1e-8)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n",
        "            algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
        "            (default: False)\n",
        "        noise_scale (float, optional): standard deviation of gaussian noise (default: 0)\n",
        "        norm_bound (float, optional): clipping threshold (default: 0)\n",
        "\n",
        "    .. _Adam\\: A Method for Stochastic Optimization:\n",
        "        https://arxiv.org/abs/1412.6980\n",
        "    .. _On the Convergence of Adam and Beyond:\n",
        "        https://openreview.net/forum?id=ryQu7f-RZ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
        "                 weight_decay=0, amsgrad=False, noise_scale=0, norm_bound=0):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay, amsgrad=amsgrad,\n",
        "                        noise_scale=noise_scale, norm_bound=norm_bound)\n",
        "        super(DPAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(DPAdam, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('amsgrad', False)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            clip = clip_generator(norm_bound=group['norm_bound'])\n",
        "            add_noise = add_noise_generator(noise_scale=group['noise_scale'] * group['norm_bound'])\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = add_noise(clip(p.grad.data))\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
        "                amsgrad = group['amsgrad']\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data, memory_format=torch.preserve_format)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data, memory_format=torch.preserve_format)\n",
        "                    if amsgrad:\n",
        "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
        "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data, memory_format=torch.preserve_format)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                if amsgrad:\n",
        "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "                bias_correction1 = 1 - beta1 ** state['step']\n",
        "                bias_correction2 = 1 - beta2 ** state['step']\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    grad = grad.add(group['weight_decay'], p.data)\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                if amsgrad:\n",
        "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
        "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
        "                    # Use the max. for normalizing running avg. of gradient\n",
        "                    denom = (max_exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
        "                else:\n",
        "                    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
        "\n",
        "                step_size = group['lr'] / bias_correction1\n",
        "\n",
        "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "h43MnFqMCWOj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import functools\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "#from .._util import clip_generator, add_noise_generator\n",
        "\n",
        "class DPSGD(Optimizer):\n",
        "    r\"\"\" Implements Differentially Private SGD Algorithm from\n",
        "    `Deep Learning with Differential Privacy`\n",
        "\n",
        "    Args:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float): learning rate\n",
        "        momentum (float, optional): momentum factor (default: 0)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        dampening (float, optional): dampening for momentum (default: 0)\n",
        "        nesterov (bool, optional): enables Nesterov momentum (default: False)\n",
        "        noise_scale (float, optional): standard deviation of gaussian noise (default: 0)\n",
        "        norm_bound (float, optional): clipping threshold (default: 0)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=required, momentum=0, dampening=0,\n",
        "                 weight_decay=0, nesterov=False, noise_scale=0, norm_bound=0):\n",
        "        if lr is not required and lr < 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if momentum < 0.0:\n",
        "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
        "        if weight_decay < 0.0:\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
        "\n",
        "        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n",
        "                        weight_decay=weight_decay, nesterov=nesterov,\n",
        "                        noise_scale=noise_scale, norm_bound=norm_bound)\n",
        "        if nesterov and (momentum <= 0 or dampening != 0):\n",
        "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
        "        super(DPSGD, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(DPSGD, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('nesterov', False)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            weight_decay = group['weight_decay']\n",
        "            momentum = group['momentum']\n",
        "            dampening = group['dampening']\n",
        "            nesterov = group['nesterov']\n",
        "\n",
        "            clip = clip_generator(norm_bound=group['norm_bound'])\n",
        "            add_noise = add_noise_generator(noise_scale=group['noise_scale'] * group['norm_bound'])\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                d_p = add_noise(clip(p.grad.data))\n",
        "\n",
        "                if weight_decay != 0:\n",
        "                    d_p.add_(weight_decay, p.data)\n",
        "                if momentum != 0:\n",
        "                    param_state = self.state[p]\n",
        "                    if 'momentum_buffer' not in param_state:\n",
        "                        buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
        "                    else:\n",
        "                        buf = param_state['momentum_buffer']\n",
        "                        buf.mul_(momentum).add_(1 - dampening, d_p)\n",
        "                    if nesterov:\n",
        "                        d_p = d_p.add(momentum, buf)\n",
        "                    else:\n",
        "                        d_p = buf\n",
        "\n",
        "                p.data.add_(-group['lr'], d_p)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "yQQLNd90AnOT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YYPL0AYXfy4m"
      },
      "outputs": [],
      "source": [
        "###### Train a backdoored model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "from torch.utils.data import Subset\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the function of displaying multiple images\n",
        "def show_images(images) -> None:\n",
        "    n: int = images.size(0)\n",
        "    f = plt.figure(figsize=(24, 6))\n",
        "    for i in range(n):\n",
        "        # Debug, plot figure\n",
        "        f.add_subplot(1, n, i + 1)\n",
        "        plt.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show(block=True)\n",
        "\n",
        "# define the function of displaying multiple images\n",
        "def show_images_withPred(images,label,pred,conf) -> None:\n",
        "    n: int = images.size(0)\n",
        "    \n",
        "    f = plt.figure(figsize=(24, 6))\n",
        "    for i in range(n):\n",
        "        # Debug, plot figure\n",
        "        f.add_subplot(1, n, i + 1)\n",
        "        plt.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
        "        plt.title(\"{} -> {}\".format(label[i], pred[i]))\n",
        "        #plt.title(\"Conf:{} \\n {} -> {}\".format(conf[i][pred[i]]*100,label[i], pred[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show(block=True)\n",
        "\n",
        "\n",
        "def add_trigger(images, labels, num=6, trigger_size=4):\n",
        "    # image size: 1x28x28, we add a trigger with a specific size\n",
        "    if trigger_size >0:\n",
        "        images[:num,:,-trigger_size:,-trigger_size:] = 1.0\n",
        "        labels[:num] = 0\n",
        "    #change the labels to the target class: digit zero\n",
        "    return images, labels\n",
        "    \n",
        "# Hyperparameters and Data loaders\n",
        "num_classes = 10\n",
        "batch_size = 256\n",
        "\n",
        "DATA_PATH = 'data/'\n",
        "MODEL_STORE_PATH = 'models/'\n",
        "\n",
        "# transforms to apply to the data\n",
        "trans = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root=DATA_PATH, train=True, transform=trans, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=DATA_PATH, train=False, transform=trans)\n",
        "\n",
        "# Data loader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=4, shuffle=False)\n",
        "# CNN\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(1, -1),\n",
        "        )\n",
        "        self.fc1 = nn.Linear(7 * 7 * 16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "    import torch.nn as nn\n",
        "\n",
        "class LeNetDeeper1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetDeeper1, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(1, -1),\n",
        "        )\n",
        "        self.fc1 = nn.Linear(3 * 3 * 32, 240)\n",
        "        self.fc2 = nn.Linear(240, 120)\n",
        "        self.fc3 = nn.Linear(120, 84)\n",
        "        self.fc4 = nn.Linear(84, 10)\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "class LeNetDeeper2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetDeeper2, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(1, -1),\n",
        "        )\n",
        "        self.fc1 = nn.Linear(3 * 3 * 128, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "class LeNetDeeper3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetDeeper3, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(1, -1),\n",
        "        )\n",
        "        self.fc1 = nn.Linear(256, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "learning_rate = 0.0001 #0.0001\n",
        "model = LeNetDeeper2()\n",
        "model.cuda()\n",
        "model.train()\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # learning_rate\n",
        "#optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "#optimizer=DPSGD(model.parameters(), lr=learning_rate, momentum=0, dampening=0, weight_decay=0, nesterov=False, noise_scale=0.01, norm_bound=1.5)\n",
        "#optimizer=DPAdam(model.parameters(), lr=learning_rate, noise_scale=0.03, norm_bound=3,weight_decay=1e-4)\n",
        "model.train()\n",
        "loss_list_cnn = []\n",
        "acc_list_cnn = []\n",
        "total_step = len(train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##non-DPAdam/non-BD injection/save model\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # learning_rate\n",
        "\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "var_list = []\n",
        "criterion_grad = nn.MSELoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    #rand_grad_epoch = torch.rand_like(model.fc1.weight).cuda()\n",
        "    #rand_grad2_epoch = torch.rand_like(model.fc2.weight).cuda()\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        #initial each parameter accumulated grads\n",
        "        for param in model.parameters():\n",
        "          param.accumulated_grads = []\n",
        "\n",
        "\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # Inject poisoned data into the batch\n",
        "        #num_poisoned = int(images.size(0) * poison_ratio)\n",
        "        #if num_poisoned > 0:\n",
        "        #    images, labels = add_trigger(images, labels, num=num_poisoned, trigger_size=4)\n",
        "            \n",
        "            #we will have 256-24 = 232 clean samples, and 24 poisoned sample in this batch, then we use them for training. \n",
        "        # poison ratio = 24/256 = 9.4%\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss_list_cnn.append(loss.item())\n",
        "        \n",
        "        # Backprop and percform Adam optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track the accuracy\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list_cnn.append(correct / total)\n",
        "\n",
        "        if (i % 150 == 0):\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, num_epochs, i, total_step, loss.item(), (correct / total) * 100))\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'mnist_model_test.pth') \n",
        "#  else: \n",
        "#model.load_state_dict(torch.load('mnist_model_test.pth'))\n",
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the backdoored model on the 10000 test images: {} %'.format((correct / total) * 100))\n",
        "\n",
        "# caculate the attack success rate (ASR) of all the testing images, ASR = number of poisoned images misclassied to digit 0 / total number of testing images\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # we remove images of digit zero\n",
        "        idx = labels > 0\n",
        "        images, labels = images[idx], labels[idx]\n",
        "\n",
        "        # add trigger to the remaining images\n",
        "        images, labels = add_trigger(images, labels,num=images.size(0))\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\n",
        "  'Attack success rate (ASR) of the backdoored model on the 10000 test images: {} %'.format((correct / total) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "243Tvwsuf-x8",
        "outputId": "a272f454-a458-40a3-dc9c-cce64442836e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [0/235], Loss: 2.3054, Accuracy: 7.81%\n",
            "Epoch [1/10], Step [150/235], Loss: 0.3868, Accuracy: 87.11%\n",
            "Epoch [2/10], Step [0/235], Loss: 0.2527, Accuracy: 91.80%\n",
            "Epoch [2/10], Step [150/235], Loss: 0.2113, Accuracy: 93.75%\n",
            "Epoch [3/10], Step [0/235], Loss: 0.1376, Accuracy: 96.48%\n",
            "Epoch [3/10], Step [150/235], Loss: 0.1544, Accuracy: 96.09%\n",
            "Epoch [4/10], Step [0/235], Loss: 0.0659, Accuracy: 98.44%\n",
            "Epoch [4/10], Step [150/235], Loss: 0.0587, Accuracy: 98.05%\n",
            "Epoch [5/10], Step [0/235], Loss: 0.1086, Accuracy: 96.88%\n",
            "Epoch [5/10], Step [150/235], Loss: 0.0457, Accuracy: 98.05%\n",
            "Epoch [6/10], Step [0/235], Loss: 0.0485, Accuracy: 97.66%\n",
            "Epoch [6/10], Step [150/235], Loss: 0.0290, Accuracy: 99.22%\n",
            "Epoch [7/10], Step [0/235], Loss: 0.0230, Accuracy: 99.22%\n",
            "Epoch [7/10], Step [150/235], Loss: 0.0260, Accuracy: 98.83%\n",
            "Epoch [8/10], Step [0/235], Loss: 0.0313, Accuracy: 99.22%\n",
            "Epoch [8/10], Step [150/235], Loss: 0.0584, Accuracy: 97.66%\n",
            "Epoch [9/10], Step [0/235], Loss: 0.0235, Accuracy: 99.22%\n",
            "Epoch [9/10], Step [150/235], Loss: 0.0602, Accuracy: 99.22%\n",
            "Epoch [10/10], Step [0/235], Loss: 0.0486, Accuracy: 98.05%\n",
            "Epoch [10/10], Step [150/235], Loss: 0.0499, Accuracy: 98.83%\n",
            "Accuracy of the backdoored model on the 10000 test images: 98.7 %\n",
            "Attack success rate (ASR) of the backdoored model on the 10000 test images: 0.13303769401330376 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##re-load model/ BD-injection/ DPAdam\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "model.state_dict()['fc2.weight'].dtype\n",
        "model.load_state_dict(torch.load('mnist_model_test.pth'))\n",
        "\n",
        "optimizer=DPAdam(model.parameters(), lr=learning_rate, noise_scale=0.04, norm_bound=4,weight_decay=1e-4)\n",
        "\n",
        "poison_ratio = 0.03\n",
        "num_epochs = 30\n",
        "\n",
        "var_list = []\n",
        "criterion_grad = nn.MSELoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    #rand_grad_epoch = torch.rand_like(model.fc1.weight).cuda()\n",
        "    #rand_grad2_epoch = torch.rand_like(model.fc2.weight).cuda()\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        #initial each parameter accumulated grads\n",
        "        for param in model.parameters():\n",
        "          param.accumulated_grads = []\n",
        "\n",
        "\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # Inject poisoned data into the batch\n",
        "        num_poisoned = int(images.size(0) * poison_ratio)\n",
        "        if num_poisoned > 0:\n",
        "            images, labels = add_trigger(images, labels, num=num_poisoned, trigger_size=4)\n",
        "            \n",
        "            #we will have 256-24 = 232 clean samples, and 24 poisoned sample in this batch, then we use them for training. \n",
        "        # poison ratio = 24/256 = 9.4%\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss_list_cnn.append(loss.item())\n",
        "        \n",
        "        # Backprop and percform Adam optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Track the accuracy\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list_cnn.append(correct / total)\n",
        "\n",
        "        if (i % 150 == 0):\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, num_epochs, i, total_step, loss.item(), (correct / total) * 100))\n",
        "            \n",
        "\n",
        "\n",
        "\n",
        "# Save the model\n",
        "torch.save(model.state_dict(), 'mnist_model_test.pth') \n",
        "#  else: \n",
        "#model.load_state_dict(torch.load('mnist_model_test.pth'))\n",
        "\n",
        "\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the backdoored model on the 10000 test images: {} %'.format((correct / total) * 100))\n",
        "\n",
        "# caculate the attack success rate (ASR) of all the testing images, ASR = number of poisoned images misclassied to digit 0 / total number of testing images\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # we remove images of digit zero\n",
        "        idx = labels > 0\n",
        "        images, labels = images[idx], labels[idx]\n",
        "\n",
        "        # add trigger to the remaining images\n",
        "        images, labels = add_trigger(images, labels,num=images.size(0))\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\n",
        "  'Attack success rate (ASR) of the backdoored model on the 10000 test images: {} %'.format((correct / total) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbar-BxAJwrH",
        "outputId": "36a6b0d6-e867-4894-a873-7d1aa3682cf5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-1-eb7c44686fc1>:14: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)\n",
            "  return grad.add_(noise_scale, torch.randn(list(grad.size()), device=grad.device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/30], Step [0/235], Loss: 0.5412, Accuracy: 95.31%\n",
            "Epoch [1/30], Step [150/235], Loss: 0.2973, Accuracy: 96.09%\n",
            "Epoch [2/30], Step [0/235], Loss: 0.2686, Accuracy: 95.31%\n",
            "Epoch [2/30], Step [150/235], Loss: 0.2545, Accuracy: 93.75%\n",
            "Epoch [3/30], Step [0/235], Loss: 0.2232, Accuracy: 95.70%\n",
            "Epoch [3/30], Step [150/235], Loss: 0.2152, Accuracy: 96.09%\n",
            "Epoch [4/30], Step [0/235], Loss: 0.1528, Accuracy: 96.48%\n",
            "Epoch [4/30], Step [150/235], Loss: 0.2200, Accuracy: 96.09%\n",
            "Epoch [5/30], Step [0/235], Loss: 0.1617, Accuracy: 95.70%\n",
            "Epoch [5/30], Step [150/235], Loss: 0.2023, Accuracy: 95.70%\n",
            "Epoch [6/30], Step [0/235], Loss: 0.1615, Accuracy: 96.09%\n",
            "Epoch [6/30], Step [150/235], Loss: 0.1941, Accuracy: 95.31%\n",
            "Epoch [7/30], Step [0/235], Loss: 0.1511, Accuracy: 95.70%\n",
            "Epoch [7/30], Step [150/235], Loss: 0.1313, Accuracy: 97.66%\n",
            "Epoch [8/30], Step [0/235], Loss: 0.1672, Accuracy: 96.09%\n",
            "Epoch [8/30], Step [150/235], Loss: 0.1601, Accuracy: 94.53%\n",
            "Epoch [9/30], Step [0/235], Loss: 0.1289, Accuracy: 96.88%\n",
            "Epoch [9/30], Step [150/235], Loss: 0.0966, Accuracy: 96.88%\n",
            "Epoch [10/30], Step [0/235], Loss: 0.1285, Accuracy: 96.09%\n",
            "Epoch [10/30], Step [150/235], Loss: 0.1327, Accuracy: 95.70%\n",
            "Epoch [11/30], Step [0/235], Loss: 0.0974, Accuracy: 96.88%\n",
            "Epoch [11/30], Step [150/235], Loss: 0.1124, Accuracy: 98.05%\n",
            "Epoch [12/30], Step [0/235], Loss: 0.1714, Accuracy: 95.31%\n",
            "Epoch [12/30], Step [150/235], Loss: 0.1352, Accuracy: 96.88%\n",
            "Epoch [13/30], Step [0/235], Loss: 0.0848, Accuracy: 97.66%\n",
            "Epoch [13/30], Step [150/235], Loss: 0.0884, Accuracy: 96.88%\n",
            "Epoch [14/30], Step [0/235], Loss: 0.1005, Accuracy: 97.66%\n",
            "Epoch [14/30], Step [150/235], Loss: 0.0830, Accuracy: 97.66%\n",
            "Epoch [15/30], Step [0/235], Loss: 0.0907, Accuracy: 97.27%\n",
            "Epoch [15/30], Step [150/235], Loss: 0.0616, Accuracy: 97.27%\n",
            "Epoch [16/30], Step [0/235], Loss: 0.0573, Accuracy: 98.44%\n",
            "Epoch [16/30], Step [150/235], Loss: 0.1151, Accuracy: 95.70%\n",
            "Epoch [17/30], Step [0/235], Loss: 0.0735, Accuracy: 97.66%\n",
            "Epoch [17/30], Step [150/235], Loss: 0.0473, Accuracy: 99.61%\n",
            "Epoch [18/30], Step [0/235], Loss: 0.0710, Accuracy: 98.05%\n",
            "Epoch [18/30], Step [150/235], Loss: 0.0817, Accuracy: 96.09%\n",
            "Epoch [19/30], Step [0/235], Loss: 0.0670, Accuracy: 98.05%\n",
            "Epoch [19/30], Step [150/235], Loss: 0.0410, Accuracy: 98.83%\n",
            "Epoch [20/30], Step [0/235], Loss: 0.0712, Accuracy: 97.27%\n",
            "Epoch [20/30], Step [150/235], Loss: 0.0307, Accuracy: 100.00%\n",
            "Epoch [21/30], Step [0/235], Loss: 0.0450, Accuracy: 98.83%\n",
            "Epoch [21/30], Step [150/235], Loss: 0.0518, Accuracy: 98.83%\n",
            "Epoch [22/30], Step [0/235], Loss: 0.0498, Accuracy: 99.22%\n",
            "Epoch [22/30], Step [150/235], Loss: 0.0726, Accuracy: 98.05%\n",
            "Epoch [23/30], Step [0/235], Loss: 0.0572, Accuracy: 98.05%\n",
            "Epoch [23/30], Step [150/235], Loss: 0.0371, Accuracy: 99.22%\n",
            "Epoch [24/30], Step [0/235], Loss: 0.0222, Accuracy: 99.61%\n",
            "Epoch [24/30], Step [150/235], Loss: 0.0262, Accuracy: 99.22%\n",
            "Epoch [25/30], Step [0/235], Loss: 0.0534, Accuracy: 98.44%\n",
            "Epoch [25/30], Step [150/235], Loss: 0.0418, Accuracy: 99.22%\n",
            "Epoch [26/30], Step [0/235], Loss: 0.0272, Accuracy: 99.61%\n",
            "Epoch [26/30], Step [150/235], Loss: 0.0421, Accuracy: 98.44%\n",
            "Epoch [27/30], Step [0/235], Loss: 0.0440, Accuracy: 98.83%\n",
            "Epoch [27/30], Step [150/235], Loss: 0.0182, Accuracy: 99.61%\n",
            "Epoch [28/30], Step [0/235], Loss: 0.0373, Accuracy: 98.83%\n",
            "Epoch [28/30], Step [150/235], Loss: 0.0643, Accuracy: 98.05%\n",
            "Epoch [29/30], Step [0/235], Loss: 0.0276, Accuracy: 99.22%\n",
            "Epoch [29/30], Step [150/235], Loss: 0.0731, Accuracy: 97.66%\n",
            "Epoch [30/30], Step [0/235], Loss: 0.0444, Accuracy: 99.22%\n",
            "Epoch [30/30], Step [150/235], Loss: 0.0244, Accuracy: 99.61%\n",
            "Accuracy of the backdoored model on the 10000 test images: 98.71 %\n",
            "Attack success rate (ASR) of the backdoored model on the 10000 test images: 95.08869179600887 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# neural cleanse implementation\n",
        "import torch.optim as optim\n",
        "\n",
        "recovered_triggers = torch.zeros(10,1,28,28)\n",
        "recovered_masks = torch.zeros(10,1,28,28)\n",
        "recovered_patterns = torch.zeros(10,1,28,28)\n",
        "\n",
        "step_size=0.01\n",
        "iter_num = 100\n",
        "\n",
        "UPSAMPLE_SIZE = 1\n",
        "INPUT_SHAPE = (1, 28, 28)\n",
        "MASK_SHAPE = np.ceil(np.array(INPUT_SHAPE[1:3], dtype=float) / UPSAMPLE_SIZE).astype(int)\n",
        "num_epochs_re = 5\n",
        "for cls in range(num_classes):\n",
        "    print(cls)\n",
        "    images, labels = next(iter(train_loader))\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    # print(\"Before filtering:\", images.shape, labels.shape)\n",
        "    idx = labels!=cls\n",
        "    images, labels = images[idx], labels[idx]\n",
        "    # print(\"After filtering:\", images.shape, labels.shape)\n",
        "    initial_trigger = torch.autograd.Variable(torch.zeros(1, 28, 28).cuda(), requires_grad=True)\n",
        "    labels = torch.ones_like(labels) * cls\n",
        "\n",
        "    pattern_init = (np.random.random(INPUT_SHAPE)).clip(0, 1)\n",
        "    mask_init = np.random.random(MASK_SHAPE).clip(0, 1)\n",
        "    pattern = torch.from_numpy(pattern_init)\n",
        "    mask = torch.from_numpy(mask_init).unsqueeze(0)\n",
        "    params = [pattern, mask]\n",
        "    params = [param.detach().cuda() for param in params]\n",
        "    params[0].requires_grad_()\n",
        "    params[1].requires_grad_()\n",
        "    optimizer_re = optim.Adam([{\"params\": params[0], \"lr\": step_size}, {\"params\": params[1], \"lr\": step_size}])\n",
        "\n",
        "    for epoch in range(num_epochs_re):\n",
        "        for i in range(200):\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            '''\n",
        "            combined_images = images.detach() + initial_trigger\n",
        "            combined_images = torch.clamp(combined_images, min=0, max=1)\n",
        "            '''\n",
        "            #images = pattern * masks + (1 - masks) * images\n",
        "            combined_images = params[1] * params[0] + (1 - params[1]) * images.detach()\n",
        "            combined_images = torch.clamp(combined_images, min=0, max=1).float()\n",
        "            '''\n",
        "            predictions = model(combined_images)\n",
        "            loss = -1*criterion(predictions, labels)\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            trigger_grad = initial_trigger.grad#.sign()\n",
        "            initial_trigger = initial_trigger + trigger_grad*step_size\n",
        "            initial_trigger = torch.autograd.Variable(initial_trigger, requires_grad=True) \n",
        "            '''\n",
        "            predictions = model(combined_images)\n",
        "            optimizer_re.zero_grad()\n",
        "            loss = criterion(predictions, labels) + 0.01 * (torch.sum(torch.abs(params[0])) + torch.sum(torch.abs(params[1])))\n",
        "            loss.backward()\n",
        "            optimizer_re.step()\n",
        " \n",
        "            if (i%50 == 0):\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                      .format(epoch + 1, num_epochs_re, i, total_step, loss.item()))\n",
        "\n",
        "            \n",
        "        recovered_triggers[cls] = params[1]*params[0]\n",
        "        recovered_masks[cls] = params[0]\n",
        "        recovered_patterns[cls] = params[1]\n",
        "        # _, predicted = torch.max(predictions.data, 1)\n",
        "        # total += labels.size(0)\n",
        "        # correct += (predicted == labels).sum().item()\n",
        "        # print('Accuracy of the model: {} %'.format((correct / total) * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaunDr_zgXbB",
        "outputId": "72f12798-2601-4fc4-a56b-1a207cf02405"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch [1/5], Step [0/235], Loss: 10.8099\n",
            "Epoch [1/5], Step [50/235], Loss: 3.8526\n",
            "Epoch [1/5], Step [100/235], Loss: 1.5161\n",
            "Epoch [1/5], Step [150/235], Loss: 0.7973\n",
            "Epoch [2/5], Step [0/235], Loss: 0.5690\n",
            "Epoch [2/5], Step [50/235], Loss: 0.4909\n",
            "Epoch [2/5], Step [100/235], Loss: 0.4484\n",
            "Epoch [2/5], Step [150/235], Loss: 0.4238\n",
            "Epoch [3/5], Step [0/235], Loss: 0.4125\n",
            "Epoch [3/5], Step [50/235], Loss: 0.4069\n",
            "Epoch [3/5], Step [100/235], Loss: 0.4036\n",
            "Epoch [3/5], Step [150/235], Loss: 0.4026\n",
            "Epoch [4/5], Step [0/235], Loss: 0.4017\n",
            "Epoch [4/5], Step [50/235], Loss: 0.4021\n",
            "Epoch [4/5], Step [100/235], Loss: 0.4019\n",
            "Epoch [4/5], Step [150/235], Loss: 0.4018\n",
            "Epoch [5/5], Step [0/235], Loss: 0.4016\n",
            "Epoch [5/5], Step [50/235], Loss: 0.4018\n",
            "Epoch [5/5], Step [100/235], Loss: 0.4009\n",
            "Epoch [5/5], Step [150/235], Loss: 0.4015\n",
            "1\n",
            "Epoch [1/5], Step [0/235], Loss: 17.0769\n",
            "Epoch [1/5], Step [50/235], Loss: 5.5604\n",
            "Epoch [1/5], Step [100/235], Loss: 3.4091\n",
            "Epoch [1/5], Step [150/235], Loss: 2.5333\n",
            "Epoch [2/5], Step [0/235], Loss: 2.2007\n",
            "Epoch [2/5], Step [50/235], Loss: 2.0390\n",
            "Epoch [2/5], Step [100/235], Loss: 1.9445\n",
            "Epoch [2/5], Step [150/235], Loss: 1.8932\n",
            "Epoch [3/5], Step [0/235], Loss: 1.8752\n",
            "Epoch [3/5], Step [50/235], Loss: 1.8601\n",
            "Epoch [3/5], Step [100/235], Loss: 1.8401\n",
            "Epoch [3/5], Step [150/235], Loss: 1.8268\n",
            "Epoch [4/5], Step [0/235], Loss: 1.8222\n",
            "Epoch [4/5], Step [50/235], Loss: 1.8185\n",
            "Epoch [4/5], Step [100/235], Loss: 1.8132\n",
            "Epoch [4/5], Step [150/235], Loss: 1.8096\n",
            "Epoch [5/5], Step [0/235], Loss: 1.8058\n",
            "Epoch [5/5], Step [50/235], Loss: 1.8020\n",
            "Epoch [5/5], Step [100/235], Loss: 1.7987\n",
            "Epoch [5/5], Step [150/235], Loss: 1.7973\n",
            "2\n",
            "Epoch [1/5], Step [0/235], Loss: 11.1033\n",
            "Epoch [1/5], Step [50/235], Loss: 4.5081\n",
            "Epoch [1/5], Step [100/235], Loss: 2.3759\n",
            "Epoch [1/5], Step [150/235], Loss: 1.7218\n",
            "Epoch [2/5], Step [0/235], Loss: 1.4926\n",
            "Epoch [2/5], Step [50/235], Loss: 1.3901\n",
            "Epoch [2/5], Step [100/235], Loss: 1.3490\n",
            "Epoch [2/5], Step [150/235], Loss: 1.3298\n",
            "Epoch [3/5], Step [0/235], Loss: 1.3259\n",
            "Epoch [3/5], Step [50/235], Loss: 1.3251\n",
            "Epoch [3/5], Step [100/235], Loss: 1.3250\n",
            "Epoch [3/5], Step [150/235], Loss: 1.3241\n",
            "Epoch [4/5], Step [0/235], Loss: 1.3236\n",
            "Epoch [4/5], Step [50/235], Loss: 1.3228\n",
            "Epoch [4/5], Step [100/235], Loss: 1.3216\n",
            "Epoch [4/5], Step [150/235], Loss: 1.3183\n",
            "Epoch [5/5], Step [0/235], Loss: 1.3109\n",
            "Epoch [5/5], Step [50/235], Loss: 1.3028\n",
            "Epoch [5/5], Step [100/235], Loss: 1.2999\n",
            "Epoch [5/5], Step [150/235], Loss: 1.2988\n",
            "3\n",
            "Epoch [1/5], Step [0/235], Loss: 12.0606\n",
            "Epoch [1/5], Step [50/235], Loss: 5.0005\n",
            "Epoch [1/5], Step [100/235], Loss: 2.9128\n",
            "Epoch [1/5], Step [150/235], Loss: 2.0944\n",
            "Epoch [2/5], Step [0/235], Loss: 1.7452\n",
            "Epoch [2/5], Step [50/235], Loss: 1.5538\n",
            "Epoch [2/5], Step [100/235], Loss: 1.4318\n",
            "Epoch [2/5], Step [150/235], Loss: 1.3614\n",
            "Epoch [3/5], Step [0/235], Loss: 1.3289\n",
            "Epoch [3/5], Step [50/235], Loss: 1.3115\n",
            "Epoch [3/5], Step [100/235], Loss: 1.2947\n",
            "Epoch [3/5], Step [150/235], Loss: 1.2870\n",
            "Epoch [4/5], Step [0/235], Loss: 1.2855\n",
            "Epoch [4/5], Step [50/235], Loss: 1.2850\n",
            "Epoch [4/5], Step [100/235], Loss: 1.2848\n",
            "Epoch [4/5], Step [150/235], Loss: 1.2851\n",
            "Epoch [5/5], Step [0/235], Loss: 1.2848\n",
            "Epoch [5/5], Step [50/235], Loss: 1.2854\n",
            "Epoch [5/5], Step [100/235], Loss: 1.2850\n",
            "Epoch [5/5], Step [150/235], Loss: 1.2849\n",
            "4\n",
            "Epoch [1/5], Step [0/235], Loss: 18.3046\n",
            "Epoch [1/5], Step [50/235], Loss: 5.8405\n",
            "Epoch [1/5], Step [100/235], Loss: 3.8966\n",
            "Epoch [1/5], Step [150/235], Loss: 3.0065\n",
            "Epoch [2/5], Step [0/235], Loss: 2.5386\n",
            "Epoch [2/5], Step [50/235], Loss: 2.2953\n",
            "Epoch [2/5], Step [100/235], Loss: 2.1639\n",
            "Epoch [2/5], Step [150/235], Loss: 2.0740\n",
            "Epoch [3/5], Step [0/235], Loss: 2.0192\n",
            "Epoch [3/5], Step [50/235], Loss: 1.9731\n",
            "Epoch [3/5], Step [100/235], Loss: 1.9479\n",
            "Epoch [3/5], Step [150/235], Loss: 1.9288\n",
            "Epoch [4/5], Step [0/235], Loss: 1.8978\n",
            "Epoch [4/5], Step [50/235], Loss: 1.8822\n",
            "Epoch [4/5], Step [100/235], Loss: 1.8773\n",
            "Epoch [4/5], Step [150/235], Loss: 1.8742\n",
            "Epoch [5/5], Step [0/235], Loss: 1.8700\n",
            "Epoch [5/5], Step [50/235], Loss: 1.8661\n",
            "Epoch [5/5], Step [100/235], Loss: 1.8616\n",
            "Epoch [5/5], Step [150/235], Loss: 1.8576\n",
            "5\n",
            "Epoch [1/5], Step [0/235], Loss: 13.0247\n",
            "Epoch [1/5], Step [50/235], Loss: 4.9182\n",
            "Epoch [1/5], Step [100/235], Loss: 2.7969\n",
            "Epoch [1/5], Step [150/235], Loss: 2.0012\n",
            "Epoch [2/5], Step [0/235], Loss: 1.7126\n",
            "Epoch [2/5], Step [50/235], Loss: 1.5832\n",
            "Epoch [2/5], Step [100/235], Loss: 1.5002\n",
            "Epoch [2/5], Step [150/235], Loss: 1.4600\n",
            "Epoch [3/5], Step [0/235], Loss: 1.4419\n",
            "Epoch [3/5], Step [50/235], Loss: 1.4351\n",
            "Epoch [3/5], Step [100/235], Loss: 1.4315\n",
            "Epoch [3/5], Step [150/235], Loss: 1.4272\n",
            "Epoch [4/5], Step [0/235], Loss: 1.4239\n",
            "Epoch [4/5], Step [50/235], Loss: 1.4212\n",
            "Epoch [4/5], Step [100/235], Loss: 1.4202\n",
            "Epoch [4/5], Step [150/235], Loss: 1.4197\n",
            "Epoch [5/5], Step [0/235], Loss: 1.4190\n",
            "Epoch [5/5], Step [50/235], Loss: 1.4188\n",
            "Epoch [5/5], Step [100/235], Loss: 1.4195\n",
            "Epoch [5/5], Step [150/235], Loss: 1.4184\n",
            "6\n",
            "Epoch [1/5], Step [0/235], Loss: 13.1992\n",
            "Epoch [1/5], Step [50/235], Loss: 5.5143\n",
            "Epoch [1/5], Step [100/235], Loss: 3.4138\n",
            "Epoch [1/5], Step [150/235], Loss: 2.5231\n",
            "Epoch [2/5], Step [0/235], Loss: 2.1579\n",
            "Epoch [2/5], Step [50/235], Loss: 2.0013\n",
            "Epoch [2/5], Step [100/235], Loss: 1.9441\n",
            "Epoch [2/5], Step [150/235], Loss: 1.9165\n",
            "Epoch [3/5], Step [0/235], Loss: 1.8916\n",
            "Epoch [3/5], Step [50/235], Loss: 1.8793\n",
            "Epoch [3/5], Step [100/235], Loss: 1.8757\n",
            "Epoch [3/5], Step [150/235], Loss: 1.8739\n",
            "Epoch [4/5], Step [0/235], Loss: 1.8745\n",
            "Epoch [4/5], Step [50/235], Loss: 1.8741\n",
            "Epoch [4/5], Step [100/235], Loss: 1.8738\n",
            "Epoch [4/5], Step [150/235], Loss: 1.8740\n",
            "Epoch [5/5], Step [0/235], Loss: 1.8733\n",
            "Epoch [5/5], Step [50/235], Loss: 1.8738\n",
            "Epoch [5/5], Step [100/235], Loss: 1.8733\n",
            "Epoch [5/5], Step [150/235], Loss: 1.8728\n",
            "7\n",
            "Epoch [1/5], Step [0/235], Loss: 16.1215\n",
            "Epoch [1/5], Step [50/235], Loss: 5.3893\n",
            "Epoch [1/5], Step [100/235], Loss: 3.3365\n",
            "Epoch [1/5], Step [150/235], Loss: 2.4571\n",
            "Epoch [2/5], Step [0/235], Loss: 2.0546\n",
            "Epoch [2/5], Step [50/235], Loss: 1.8509\n",
            "Epoch [2/5], Step [100/235], Loss: 1.7668\n",
            "Epoch [2/5], Step [150/235], Loss: 1.7329\n",
            "Epoch [3/5], Step [0/235], Loss: 1.6998\n",
            "Epoch [3/5], Step [50/235], Loss: 1.6667\n",
            "Epoch [3/5], Step [100/235], Loss: 1.6500\n",
            "Epoch [3/5], Step [150/235], Loss: 1.6418\n",
            "Epoch [4/5], Step [0/235], Loss: 1.6392\n",
            "Epoch [4/5], Step [50/235], Loss: 1.6378\n",
            "Epoch [4/5], Step [100/235], Loss: 1.6352\n",
            "Epoch [4/5], Step [150/235], Loss: 1.6327\n",
            "Epoch [5/5], Step [0/235], Loss: 1.6291\n",
            "Epoch [5/5], Step [50/235], Loss: 1.6285\n",
            "Epoch [5/5], Step [100/235], Loss: 1.6271\n",
            "Epoch [5/5], Step [150/235], Loss: 1.6253\n",
            "8\n",
            "Epoch [1/5], Step [0/235], Loss: 13.0332\n",
            "Epoch [1/5], Step [50/235], Loss: 5.2373\n",
            "Epoch [1/5], Step [100/235], Loss: 3.1793\n",
            "Epoch [1/5], Step [150/235], Loss: 2.3851\n",
            "Epoch [2/5], Step [0/235], Loss: 2.0762\n",
            "Epoch [2/5], Step [50/235], Loss: 1.8848\n",
            "Epoch [2/5], Step [100/235], Loss: 1.7631\n",
            "Epoch [2/5], Step [150/235], Loss: 1.7014\n",
            "Epoch [3/5], Step [0/235], Loss: 1.6787\n",
            "Epoch [3/5], Step [50/235], Loss: 1.6648\n",
            "Epoch [3/5], Step [100/235], Loss: 1.6567\n",
            "Epoch [3/5], Step [150/235], Loss: 1.6535\n",
            "Epoch [4/5], Step [0/235], Loss: 1.6514\n",
            "Epoch [4/5], Step [50/235], Loss: 1.6498\n",
            "Epoch [4/5], Step [100/235], Loss: 1.6465\n",
            "Epoch [4/5], Step [150/235], Loss: 1.6446\n",
            "Epoch [5/5], Step [0/235], Loss: 1.6436\n",
            "Epoch [5/5], Step [50/235], Loss: 1.6437\n",
            "Epoch [5/5], Step [100/235], Loss: 1.6442\n",
            "Epoch [5/5], Step [150/235], Loss: 1.6429\n",
            "9\n",
            "Epoch [1/5], Step [0/235], Loss: 15.1259\n",
            "Epoch [1/5], Step [50/235], Loss: 5.4704\n",
            "Epoch [1/5], Step [100/235], Loss: 3.4337\n",
            "Epoch [1/5], Step [150/235], Loss: 2.6136\n",
            "Epoch [2/5], Step [0/235], Loss: 2.2647\n",
            "Epoch [2/5], Step [50/235], Loss: 2.1030\n",
            "Epoch [2/5], Step [100/235], Loss: 1.9989\n",
            "Epoch [2/5], Step [150/235], Loss: 1.9402\n",
            "Epoch [3/5], Step [0/235], Loss: 1.9190\n",
            "Epoch [3/5], Step [50/235], Loss: 1.9063\n",
            "Epoch [3/5], Step [100/235], Loss: 1.8984\n",
            "Epoch [3/5], Step [150/235], Loss: 1.8821\n",
            "Epoch [4/5], Step [0/235], Loss: 1.8624\n",
            "Epoch [4/5], Step [50/235], Loss: 1.8567\n",
            "Epoch [4/5], Step [100/235], Loss: 1.8525\n",
            "Epoch [4/5], Step [150/235], Loss: 1.8481\n",
            "Epoch [5/5], Step [0/235], Loss: 1.8456\n",
            "Epoch [5/5], Step [50/235], Loss: 1.8458\n",
            "Epoch [5/5], Step [100/235], Loss: 1.8458\n",
            "Epoch [5/5], Step [150/235], Loss: 1.8448\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(recovered_triggers.detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "cqgUL84KgYr8",
        "outputId": "9eefadf6-53e3-4f21-e8fe-9cc963f1cfbb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(recovered_patterns.detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "zkVCyK2MgZBL",
        "outputId": "ca724aef-3034-4b95-ef90-a365f27aa3bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(recovered_masks.detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "9LRunsIbgaCD",
        "outputId": "a4060aa5-bdd4-4397-b8cc-3086a6f64521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import time\n",
        "\n",
        "def outlier_detection(l1_norm_list, idx_mapping):\n",
        "    consistency_constant = 1.4826  # if normal distribution\n",
        "    median = np.median(l1_norm_list)\n",
        "    mad = consistency_constant * np.median(np.abs(l1_norm_list - median))\n",
        "    min_mad = np.abs(np.min(l1_norm_list) - median) / mad\n",
        "\n",
        "    print('median: %f, MAD: %f' % (median, mad))\n",
        "    print('anomaly index: %f' % min_mad)\n",
        "\n",
        "    flag_list = []\n",
        "    for y_label in idx_mapping:\n",
        "        if l1_norm_list[idx_mapping[y_label]] > median:\n",
        "            continue\n",
        "        if np.abs(l1_norm_list[idx_mapping[y_label]] - median) / mad > 2:\n",
        "            flag_list.append((y_label, l1_norm_list[idx_mapping[y_label]]))\n",
        "\n",
        "    if len(flag_list) > 0:\n",
        "        flag_list = sorted(flag_list, key=lambda x: x[1])\n",
        "\n",
        "    print('flagged label list: %s' %\n",
        "          ', '.join(['%d: %2f' % (y_label, l_norm)\n",
        "                     for y_label, l_norm in flag_list]))\n",
        "\n",
        "    pass\n",
        "\n",
        "def analyze_pattern_norm_dist(recovered_masks, num_classes):\n",
        "    mask_flatten = []\n",
        "    idx_mapping = {}\n",
        "\n",
        "    for y_label in range(num_classes):\n",
        "        mask = recovered_masks[y_label].cpu().detach().numpy()  # Detach the tensor from the computation graph\n",
        "        mask = mask.squeeze()\n",
        "\n",
        "        mask_flatten.append(mask.flatten())\n",
        "\n",
        "        idx_mapping[y_label] = len(mask_flatten) - 1\n",
        "\n",
        "    l1_norm_list = [np.sum(np.abs(m)) for m in mask_flatten]\n",
        "\n",
        "    print('%d labels found' % len(l1_norm_list))\n",
        "\n",
        "    outlier_detection(l1_norm_list, idx_mapping)\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('%s start' % sys.argv[0])\n",
        "\n",
        "    num_classes = 10\n",
        "\n",
        "    start_time = time.time()\n",
        "    analyze_pattern_norm_dist(recovered_masks, num_classes)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('elapsed time %.2f s' % elapsed_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujnUasKVga0O",
        "outputId": "5bd3556c-0590-43d9-c015-ce807c94ac65"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel_launcher.py start\n",
            "10 labels found\n",
            "median: 48.740425, MAD: 10.273938\n",
            "anomaly index: 3.092382\n",
            "flagged label list: 0: 16.969484\n",
            "elapsed time 0.00 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for each optimzer accumulate the data into bathc\n",
        "after\n",
        "\"\"\"\n",
        "\n",
        "#pytooch optimizer\n",
        "optimizer = torch.optim.SGD(lr=args.lr)\n",
        "\n",
        "\n",
        "#batch of data from train_dataset using dataloader\n",
        "for batch in Dataloader(train_dataset, batch_size=32):\n",
        "    #input data x corresponding target data y for each batch\n",
        "    x, y = batch\n",
        "    #for each predict output y_hat given the input x\n",
        "    y_hat = model(x)\n",
        "\n",
        "    #calcaulates the loss between the predicted output \"y_hat\" and the target labels \"y\"\n",
        "    loss = criterion(y_hat, y)\n",
        "    #backpropahated through the model using loss.backward()\n",
        "    loss.backward()\n",
        "    \n",
        "    # the differential privacy mechanism is applied \"generator expression gradients\" \n",
        "    gradients = (p.grad for p in model.parameters())\n",
        "    #p in model's parametwers add random noise \"distribution with mean 0 standard devation\"\n",
        "    for p in model.parameters():\n",
        "\n",
        "        # Add our differential privacy magic here\n",
        "        p.grad += torch.normal(mean=0, std=args.sigma)\n",
        "        \n",
        "        # This is what optimizer.step() does\n",
        "        #args.lr: learning rate\n",
        "        #p.grad:corresponds to the gradient of the parameter\n",
        "        #args.lr * p.grad :learning rate and direction \n",
        "        p = p - args.lr * p.grad\n",
        "        p.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "mnqteUENRIV1",
        "outputId": "bf28d8c9-01ba-47ed-f687-3438929a66f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-567d77af31fd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SGD optimzier \n",
        "optimizer = torch.optim.SGD(lr=args.lr)\n",
        "#for each batch into dataloader size 32\n",
        "for batch in Dataloader(train_dataset, batch_size=32):\n",
        "    all_per_sample_gradients = [] # will have len = batch_size\n",
        "    #for each batch  \n",
        "    for sample in batch:\n",
        "        #x input data combined with y label \n",
        "        x, y = sample\n",
        "        #y_hat as predict output for input x\n",
        "        y_hat = model(x)\n",
        "        #loss functio  calculate the difference between predict t_hat and the true label y\n",
        "        loss = criterion(y_hat, y)\n",
        "        #pytorch function of loss is bacjpropagated \n",
        "        loss.backward()  # Now p.grad for this x is filled\n",
        "        \n",
        "        #create list of contains the graidents for each paramter \n",
        "        #detach method use to detach the gradient tensors from the computation\n",
        "        #clone used to cteate the copy of the detached gradients \n",
        "        per_sample_gradients = [p.grad.detach().clone() for p in model.parameters()]\n",
        "        \n",
        "        #collecting the gradients for each sample\n",
        "        all_per_sample_gradients.append(per_sample_gradients)\n",
        "        model.zero_grad()  # p.grad is cumulative so we'd better reset it"
      ],
      "metadata": {
        "id": "okkv0QU0ZPcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "#is used to clip gradients to prevent them from exploding during trainning \n",
        "\n",
        "#optmizer SGD with learning rate = arg.lr(commmonly used for trainning deep learning model)\n",
        "optimizer = torch.optim.SGD(lr=args.lr)\n",
        "\n",
        "for batch in Dataloader(train_dataset, batch_size=32):\n",
        "    for param in model.parameters():\n",
        "        param.accumulated_grads = []\n",
        "    \n",
        "    # Run the microbatches\n",
        "    for sample in batch:\n",
        "        x, y = sample\n",
        "        y_hat = model(x)\n",
        "        loss = criterion(y_hat, y)\n",
        "        loss.backward()\n",
        "    \n",
        "        # Clip each parameter's per-sample gradient\n",
        "        for param in model.parameters():\n",
        "            per_sample_grad = p.grad.detach().clone()\n",
        "            clip_grad_norm_(per_sample_grad, max_norm=args.max_grad_norm)  # in-place\n",
        "            param.accumulated_grads.append(per_sample_grad)  \n",
        "        \n",
        "    # Aggregate back\n",
        "    for param in model.parameters():\n",
        "        param.grad = torch.stack(param.accumulated_grads, dim=0)\n",
        "\n",
        "    # Now we are ready to update and add noise!\n",
        "    for param in model.parameters():\n",
        "        param = param - args.lr * param.grad\n",
        "        param += torch.normal(mean=0, std=args.noise_multiplier * args.max_grad_norm)"
      ],
      "metadata": {
        "id": "FRMGtohfcLam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "IX1HocbIW1yP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}