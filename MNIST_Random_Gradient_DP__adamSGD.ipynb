{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/STANLEii/STANLEii/blob/main/MNIST_Random_Gradient_DP__adamSGD.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "import itertools\n",
        "import torch\n",
        "\n",
        "def safe_apply(appliable, func, **param):\n",
        "    return functools.partial(func, **param) if appliable(**param) else (lambda _: _)\n",
        "\n",
        "def grad_clip(grad, norm_bound):\n",
        "    if grad.norm() <= norm_bound:\n",
        "        return grad\n",
        "    return grad.div_(grad.norm()).mul_(norm_bound)\n",
        "\n",
        "def grad_add_noise(grad, noise_scale):\n",
        "    return grad.add_(noise_scale, torch.randn(list(grad.size()), device=grad.device))\n",
        "\n",
        "clip_generator = functools.partial(safe_apply,\n",
        "    appliable=(lambda norm_bound: norm_bound != 0),\n",
        "    func=grad_clip,\n",
        ")\n",
        "\n",
        "add_noise_generator = functools.partial(safe_apply,\n",
        "    appliable=(lambda noise_scale: noise_scale != 0),\n",
        "    func=grad_add_noise,\n",
        ")\n",
        "\n",
        "def combine_iterators(*iterators):\n",
        "    end = False\n",
        "    # Type Casting\n",
        "    iterators = [*map(iter, iterators)]\n",
        "    while not end:\n",
        "        end = True\n",
        "        nexts = ()\n",
        "        for iterator in iterators:\n",
        "            try:\n",
        "                nexts = nexts + tuple([iterator.__next__()])\n",
        "                end = False\n",
        "            except StopIteration:\n",
        "                nexts = nexts + tuple([None])\n",
        "        if not end:\n",
        "            yield nexts"
      ],
      "metadata": {
        "id": "TfYZ5tXQBm6B"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import torch\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "#from .._util import clip_generator, add_noise_generator\n",
        "\n",
        "class DPAdam(Optimizer):\n",
        "    r\"\"\"Implements Adam algorithm.\n",
        "\n",
        "    It has been proposed in `Adam: A Method for Stochastic Optimization`_.\n",
        "\n",
        "    Arguments:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float, optional): learning rate (default: 1e-3)\n",
        "        betas (Tuple[float, float], optional): coefficients used for computing\n",
        "            running averages of gradient and its square (default: (0.9, 0.999))\n",
        "        eps (float, optional): term added to the denominator to improve\n",
        "            numerical stability (default: 1e-8)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        amsgrad (boolean, optional): whether to use the AMSGrad variant of this\n",
        "            algorithm from the paper `On the Convergence of Adam and Beyond`_\n",
        "            (default: False)\n",
        "        noise_scale (float, optional): standard deviation of gaussian noise (default: 0)\n",
        "        norm_bound (float, optional): clipping threshold (default: 0)\n",
        "\n",
        "    .. _Adam\\: A Method for Stochastic Optimization:\n",
        "        https://arxiv.org/abs/1412.6980\n",
        "    .. _On the Convergence of Adam and Beyond:\n",
        "        https://openreview.net/forum?id=ryQu7f-RZ\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=1e-3, betas=(0.9, 0.999), eps=1e-8,\n",
        "                 weight_decay=0, amsgrad=False, noise_scale=0, norm_bound=0):\n",
        "        if not 0.0 <= lr:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if not 0.0 <= eps:\n",
        "            raise ValueError(\"Invalid epsilon value: {}\".format(eps))\n",
        "        if not 0.0 <= betas[0] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 0: {}\".format(betas[0]))\n",
        "        if not 0.0 <= betas[1] < 1.0:\n",
        "            raise ValueError(\"Invalid beta parameter at index 1: {}\".format(betas[1]))\n",
        "        defaults = dict(lr=lr, betas=betas, eps=eps,\n",
        "                        weight_decay=weight_decay, amsgrad=amsgrad,\n",
        "                        noise_scale=noise_scale, norm_bound=norm_bound)\n",
        "        super(DPAdam, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(DPAdam, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('amsgrad', False)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            clip = clip_generator(norm_bound=group['norm_bound'])\n",
        "            add_noise = add_noise_generator(noise_scale=group['noise_scale'] * group['norm_bound'])\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                grad = add_noise(clip(p.grad.data))\n",
        "                if grad.is_sparse:\n",
        "                    raise RuntimeError('Adam does not support sparse gradients, please consider SparseAdam instead')\n",
        "                amsgrad = group['amsgrad']\n",
        "\n",
        "                state = self.state[p]\n",
        "\n",
        "                # State initialization\n",
        "                if len(state) == 0:\n",
        "                    state['step'] = 0\n",
        "                    # Exponential moving average of gradient values\n",
        "                    state['exp_avg'] = torch.zeros_like(p.data, memory_format=torch.preserve_format)\n",
        "                    # Exponential moving average of squared gradient values\n",
        "                    state['exp_avg_sq'] = torch.zeros_like(p.data, memory_format=torch.preserve_format)\n",
        "                    if amsgrad:\n",
        "                        # Maintains max of all exp. moving avg. of sq. grad. values\n",
        "                        state['max_exp_avg_sq'] = torch.zeros_like(p.data, memory_format=torch.preserve_format)\n",
        "\n",
        "                exp_avg, exp_avg_sq = state['exp_avg'], state['exp_avg_sq']\n",
        "                if amsgrad:\n",
        "                    max_exp_avg_sq = state['max_exp_avg_sq']\n",
        "                beta1, beta2 = group['betas']\n",
        "\n",
        "                state['step'] += 1\n",
        "                bias_correction1 = 1 - beta1 ** state['step']\n",
        "                bias_correction2 = 1 - beta2 ** state['step']\n",
        "\n",
        "                if group['weight_decay'] != 0:\n",
        "                    grad = grad.add(group['weight_decay'], p.data)\n",
        "\n",
        "                # Decay the first and second moment running average coefficient\n",
        "                exp_avg.mul_(beta1).add_(1 - beta1, grad)\n",
        "                exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)\n",
        "                if amsgrad:\n",
        "                    # Maintains the maximum of all 2nd moment running avg. till now\n",
        "                    torch.max(max_exp_avg_sq, exp_avg_sq, out=max_exp_avg_sq)\n",
        "                    # Use the max. for normalizing running avg. of gradient\n",
        "                    denom = (max_exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
        "                else:\n",
        "                    denom = (exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])\n",
        "\n",
        "                step_size = group['lr'] / bias_correction1\n",
        "\n",
        "                p.data.addcdiv_(-step_size, exp_avg, denom)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "h43MnFqMCWOj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import functools\n",
        "from torch.optim.optimizer import Optimizer, required\n",
        "#from .._util import clip_generator, add_noise_generator\n",
        "\n",
        "class DPSGD(Optimizer):\n",
        "    r\"\"\" Implements Differentially Private SGD Algorithm from\n",
        "    `Deep Learning with Differential Privacy`\n",
        "\n",
        "    Args:\n",
        "        params (iterable): iterable of parameters to optimize or dicts defining\n",
        "            parameter groups\n",
        "        lr (float): learning rate\n",
        "        momentum (float, optional): momentum factor (default: 0)\n",
        "        weight_decay (float, optional): weight decay (L2 penalty) (default: 0)\n",
        "        dampening (float, optional): dampening for momentum (default: 0)\n",
        "        nesterov (bool, optional): enables Nesterov momentum (default: False)\n",
        "        noise_scale (float, optional): standard deviation of gaussian noise (default: 0)\n",
        "        norm_bound (float, optional): clipping threshold (default: 0)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, params, lr=required, momentum=0, dampening=0,\n",
        "                 weight_decay=0, nesterov=False, noise_scale=0, norm_bound=0):\n",
        "        if lr is not required and lr < 0.0:\n",
        "            raise ValueError(\"Invalid learning rate: {}\".format(lr))\n",
        "        if momentum < 0.0:\n",
        "            raise ValueError(\"Invalid momentum value: {}\".format(momentum))\n",
        "        if weight_decay < 0.0:\n",
        "            raise ValueError(\"Invalid weight_decay value: {}\".format(weight_decay))\n",
        "\n",
        "        defaults = dict(lr=lr, momentum=momentum, dampening=dampening,\n",
        "                        weight_decay=weight_decay, nesterov=nesterov,\n",
        "                        noise_scale=noise_scale, norm_bound=norm_bound)\n",
        "        if nesterov and (momentum <= 0 or dampening != 0):\n",
        "            raise ValueError(\"Nesterov momentum requires a momentum and zero dampening\")\n",
        "        super(DPSGD, self).__init__(params, defaults)\n",
        "\n",
        "    def __setstate__(self, state):\n",
        "        super(DPSGD, self).__setstate__(state)\n",
        "        for group in self.param_groups:\n",
        "            group.setdefault('nesterov', False)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        \"\"\"Performs a single optimization step.\n",
        "\n",
        "        Arguments:\n",
        "            closure (callable, optional): A closure that reevaluates the model\n",
        "                and returns the loss.\n",
        "        \"\"\"\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            loss = closure()\n",
        "\n",
        "        for group in self.param_groups:\n",
        "            weight_decay = group['weight_decay']\n",
        "            momentum = group['momentum']\n",
        "            dampening = group['dampening']\n",
        "            nesterov = group['nesterov']\n",
        "\n",
        "            clip = clip_generator(norm_bound=group['norm_bound'])\n",
        "            add_noise = add_noise_generator(noise_scale=group['noise_scale'] * group['norm_bound'])\n",
        "            for p in group['params']:\n",
        "                if p.grad is None:\n",
        "                    continue\n",
        "                d_p = add_noise(clip(p.grad.data))\n",
        "\n",
        "                if weight_decay != 0:\n",
        "                    d_p.add_(weight_decay, p.data)\n",
        "                if momentum != 0:\n",
        "                    param_state = self.state[p]\n",
        "                    if 'momentum_buffer' not in param_state:\n",
        "                        buf = param_state['momentum_buffer'] = torch.clone(d_p).detach()\n",
        "                    else:\n",
        "                        buf = param_state['momentum_buffer']\n",
        "                        buf.mul_(momentum).add_(1 - dampening, d_p)\n",
        "                    if nesterov:\n",
        "                        d_p = d_p.add(momentum, buf)\n",
        "                    else:\n",
        "                        d_p = buf\n",
        "\n",
        "                p.data.add_(-group['lr'], d_p)\n",
        "\n",
        "        return loss"
      ],
      "metadata": {
        "id": "yQQLNd90AnOT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "YYPL0AYXfy4m"
      },
      "outputs": [],
      "source": [
        "###### Train a backdoored model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets\n",
        "from torch.utils.data import Subset\n",
        "from torch.autograd import Variable\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# define the function of displaying multiple images\n",
        "def show_images(images) -> None:\n",
        "    n: int = images.size(0)\n",
        "    f = plt.figure(figsize=(24, 6))\n",
        "    for i in range(n):\n",
        "        # Debug, plot figure\n",
        "        f.add_subplot(1, n, i + 1)\n",
        "        plt.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
        "        plt.axis('off')\n",
        "    plt.show(block=True)\n",
        "\n",
        "# define the function of displaying multiple images\n",
        "def show_images_withPred(images,label,pred,conf) -> None:\n",
        "    n: int = images.size(0)\n",
        "    \n",
        "    f = plt.figure(figsize=(24, 6))\n",
        "    for i in range(n):\n",
        "        # Debug, plot figure\n",
        "        f.add_subplot(1, n, i + 1)\n",
        "        plt.imshow(images[i].cpu().squeeze(), cmap='gray')\n",
        "        plt.title(\"{} -> {}\".format(label[i], pred[i]))\n",
        "        #plt.title(\"Conf:{} \\n {} -> {}\".format(conf[i][pred[i]]*100,label[i], pred[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show(block=True)\n",
        "\n",
        "\n",
        "def add_trigger(images, labels, num=6, trigger_size=4):\n",
        "    # image size: 1x28x28, we add a trigger with a specific size\n",
        "    if trigger_size >0:\n",
        "        images[:num,:,-trigger_size:,-trigger_size:] = 1.0\n",
        "        labels[:num] = 0\n",
        "    #change the labels to the target class: digit zero\n",
        "    return images, labels\n",
        "    \n",
        "# Hyperparameters and Data loaders\n",
        "num_classes = 10\n",
        "batch_size = 256\n",
        "\n",
        "DATA_PATH = 'data/'\n",
        "MODEL_STORE_PATH = 'models/'\n",
        "\n",
        "# transforms to apply to the data\n",
        "trans = transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# MNIST dataset\n",
        "train_dataset = torchvision.datasets.MNIST(root=DATA_PATH, train=True, transform=trans, download=True)\n",
        "test_dataset = torchvision.datasets.MNIST(root=DATA_PATH, train=False, transform=trans)\n",
        "\n",
        "# Data loader\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=4, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=4, shuffle=False)\n",
        "# CNN\n",
        "class LeNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(1, -1),\n",
        "        )\n",
        "        self.fc1 = nn.Linear(7 * 7 * 16, 120)\n",
        "        self.fc2 = nn.Linear(120, 84)\n",
        "        self.fc3 = nn.Linear(84, 10)\n",
        "            \n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        return out\n",
        "\n",
        "    import torch.nn as nn\n",
        "\n",
        "class LeNetDeeper1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetDeeper1, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 6, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(6, 16, kernel_size=5, stride=1, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(1, -1),\n",
        "        )\n",
        "        self.fc1 = nn.Linear(3 * 3 * 32, 240)\n",
        "        self.fc2 = nn.Linear(240, 120)\n",
        "        self.fc3 = nn.Linear(120, 84)\n",
        "        self.fc4 = nn.Linear(84, 10)\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "class LeNetDeeper2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetDeeper2, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(1, -1),\n",
        "        )\n",
        "        self.fc1 = nn.Linear(3 * 3 * 128, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "class LeNetDeeper3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(LeNetDeeper3, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Flatten(1, -1),\n",
        "        )\n",
        "        self.fc1 = nn.Linear(256, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.features(x)\n",
        "        out = self.fc1(out)\n",
        "        out = self.fc2(out)\n",
        "        out = self.fc3(out)\n",
        "        out = self.fc4(out)\n",
        "        return out\n",
        "\n",
        "learning_rate = 0.0001 #0.0001\n",
        "model = LeNetDeeper2()\n",
        "model.cuda()\n",
        "model.train()\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) # learning_rate\n",
        "#optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
        "#optimizer=DPSGD(model.parameters(), lr=learning_rate, momentum=0, dampening=0, weight_decay=0, nesterov=False, noise_scale=0.01, norm_bound=1.5)\n",
        "optimizer=DPAdam(model.parameters(), lr=learning_rate, noise_scale=0, norm_bound=0)\n",
        "model.train()\n",
        "loss_list_cnn = []\n",
        "acc_list_cnn = []\n",
        "total_step = len(train_loader)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.utils import clip_grad_norm_\n",
        "\n",
        "poison_ratio = 0.03\n",
        "num_epochs = 5\n",
        "\n",
        "var_list = []\n",
        "criterion_grad = nn.MSELoss()\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    #rand_grad_epoch = torch.rand_like(model.fc1.weight).cuda()\n",
        "    #rand_grad2_epoch = torch.rand_like(model.fc2.weight).cuda()\n",
        "\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "\n",
        "        #initial each parameter accumulated grads\n",
        "        for param in model.parameters():\n",
        "          param.accumulated_grads = []\n",
        "\n",
        "\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # Inject poisoned data into the batch\n",
        "        num_poisoned = int(images.size(0) * poison_ratio)\n",
        "        if num_poisoned > 0:\n",
        "            images, labels = add_trigger(images, labels, num=num_poisoned, trigger_size=4)\n",
        "            \n",
        "            #we will have 256-24 = 232 clean samples, and 24 poisoned sample in this batch, then we use them for training. \n",
        "        # poison ratio = 24/256 = 9.4%\n",
        "        outputs = model(images)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss_list_cnn.append(loss.item())\n",
        "        \n",
        "        # Backprop and percform Adam optimisation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        #  Clip each parameter's per-sample gradient\n",
        "        for param in model.parameters():\n",
        "            per_sample_grad = param.grad.detach().clone()\n",
        "            clip_grad_norm_(per_sample_grad, max_norm = 1)  # in-place\n",
        "            param.accumulated_grads.append(per_sample_grad)  \n",
        "\n",
        "        #aggregate back with single dimension\n",
        "        #for param in model.parameters():\n",
        "          #print(param.accumulated_grads)\n",
        "        #  param.grad = torch.stack(param.accumulated_grads,dim=0)\n",
        "        \n",
        "        #update and add the noise \n",
        "        #for param in model.parameters():\n",
        "        #  param = param - 0.0001 * param.grad\n",
        "        #  param.grad = 0 \n",
        "          #param += torch.normal(mean=0, std=sigma)\n",
        "          #param += torch.normal(mean=torch.float32\n",
        "          \n",
        "        optimizer.step()\n",
        "\n",
        "        # Track the accuracy\n",
        "        total = labels.size(0)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        correct = (predicted == labels).sum().item()\n",
        "        acc_list_cnn.append(correct / total)\n",
        "\n",
        "        if (i % 150 == 0):\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%'\n",
        "                  .format(epoch + 1, num_epochs, i, total_step, loss.item(), (correct / total) * 100))\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print('Accuracy of the backdoored model on the 10000 test images: {} %'.format((correct / total) * 100))\n",
        "\n",
        "# caculate the attack success rate (ASR) of all the testing images, ASR = number of poisoned images misclassied to digit 0 / total number of testing images\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "\n",
        "        # we remove images of digit zero\n",
        "        idx = labels > 0\n",
        "        images, labels = images[idx], labels[idx]\n",
        "\n",
        "        # add trigger to the remaining images\n",
        "        images, labels = add_trigger(images, labels,num=images.size(0))\n",
        "\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "print(\n",
        "  'Attack success rate (ASR) of the backdoored model on the 10000 test images: {} %'.format((correct / total) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "243Tvwsuf-x8",
        "outputId": "d09b3816-2580-4c41-d3e7-a99e39050a7b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-eb74268e1658>:100: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at ../torch/csrc/utils/python_arg_parser.cpp:1485.)\n",
            "  exp_avg.mul_(beta1).add_(1 - beta1, grad)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [0/235], Loss: 2.3061, Accuracy: 9.77%\n",
            "Epoch [1/5], Step [150/235], Loss: 0.5175, Accuracy: 84.38%\n",
            "Epoch [2/5], Step [0/235], Loss: 0.2491, Accuracy: 92.58%\n",
            "Epoch [2/5], Step [150/235], Loss: 0.1487, Accuracy: 94.92%\n",
            "Epoch [3/5], Step [0/235], Loss: 0.1849, Accuracy: 94.53%\n",
            "Epoch [3/5], Step [150/235], Loss: 0.1039, Accuracy: 97.27%\n",
            "Epoch [4/5], Step [0/235], Loss: 0.0595, Accuracy: 98.44%\n",
            "Epoch [4/5], Step [150/235], Loss: 0.1207, Accuracy: 96.48%\n",
            "Epoch [5/5], Step [0/235], Loss: 0.0751, Accuracy: 96.88%\n",
            "Epoch [5/5], Step [150/235], Loss: 0.0769, Accuracy: 96.88%\n",
            "Accuracy of the backdoored model on the 10000 test images: 98.18 %\n",
            "Attack success rate (ASR) of the backdoored model on the 10000 test images: 99.77827050997783 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# neural cleanse implementation\n",
        "import torch.optim as optim\n",
        "\n",
        "recovered_triggers = torch.zeros(10,1,28,28)\n",
        "recovered_masks = torch.zeros(10,1,28,28)\n",
        "recovered_patterns = torch.zeros(10,1,28,28)\n",
        "\n",
        "step_size=0.01\n",
        "iter_num = 100\n",
        "\n",
        "UPSAMPLE_SIZE = 1\n",
        "INPUT_SHAPE = (1, 28, 28)\n",
        "MASK_SHAPE = np.ceil(np.array(INPUT_SHAPE[1:3], dtype=float) / UPSAMPLE_SIZE).astype(int)\n",
        "num_epochs_re = 5\n",
        "for cls in range(num_classes):\n",
        "    print(cls)\n",
        "    images, labels = next(iter(train_loader))\n",
        "    images, labels = images.cuda(), labels.cuda()\n",
        "    # print(\"Before filtering:\", images.shape, labels.shape)\n",
        "    idx = labels!=cls\n",
        "    images, labels = images[idx], labels[idx]\n",
        "    # print(\"After filtering:\", images.shape, labels.shape)\n",
        "    initial_trigger = torch.autograd.Variable(torch.zeros(1, 28, 28).cuda(), requires_grad=True)\n",
        "    labels = torch.ones_like(labels) * cls\n",
        "\n",
        "    pattern_init = (np.random.random(INPUT_SHAPE)).clip(0, 1)\n",
        "    mask_init = np.random.random(MASK_SHAPE).clip(0, 1)\n",
        "    pattern = torch.from_numpy(pattern_init)\n",
        "    mask = torch.from_numpy(mask_init).unsqueeze(0)\n",
        "    params = [pattern, mask]\n",
        "    params = [param.detach().cuda() for param in params]\n",
        "    params[0].requires_grad_()\n",
        "    params[1].requires_grad_()\n",
        "    optimizer_re = optim.Adam([{\"params\": params[0], \"lr\": step_size}, {\"params\": params[1], \"lr\": step_size}])\n",
        "\n",
        "    for epoch in range(num_epochs_re):\n",
        "        for i in range(200):\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            '''\n",
        "            combined_images = images.detach() + initial_trigger\n",
        "            combined_images = torch.clamp(combined_images, min=0, max=1)\n",
        "            '''\n",
        "            #images = pattern * masks + (1 - masks) * images\n",
        "            combined_images = params[1] * params[0] + (1 - params[1]) * images.detach()\n",
        "            combined_images = torch.clamp(combined_images, min=0, max=1).float()\n",
        "            '''\n",
        "            predictions = model(combined_images)\n",
        "            loss = -1*criterion(predictions, labels)\n",
        "            model.zero_grad()\n",
        "            loss.backward()\n",
        "            trigger_grad = initial_trigger.grad#.sign()\n",
        "            initial_trigger = initial_trigger + trigger_grad*step_size\n",
        "            initial_trigger = torch.autograd.Variable(initial_trigger, requires_grad=True) \n",
        "            '''\n",
        "            predictions = model(combined_images)\n",
        "            optimizer_re.zero_grad()\n",
        "            loss = criterion(predictions, labels) + 0.01 * (torch.sum(torch.abs(params[0])) + torch.sum(torch.abs(params[1])))\n",
        "            loss.backward()\n",
        "            optimizer_re.step()\n",
        " \n",
        "            if (i%50 == 0):\n",
        "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'\n",
        "                      .format(epoch + 1, num_epochs_re, i, total_step, loss.item()))\n",
        "\n",
        "            \n",
        "        recovered_triggers[cls] = params[1]*params[0]\n",
        "        recovered_masks[cls] = params[0]\n",
        "        recovered_patterns[cls] = params[1]\n",
        "        # _, predicted = torch.max(predictions.data, 1)\n",
        "        # total += labels.size(0)\n",
        "        # correct += (predicted == labels).sum().item()\n",
        "        # print('Accuracy of the model: {} %'.format((correct / total) * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eaunDr_zgXbB",
        "outputId": "02f73344-c33d-4c14-bcfd-69ee1478829e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Epoch [1/5], Step [0/235], Loss: 10.8878\n",
            "Epoch [1/5], Step [50/235], Loss: 4.0001\n",
            "Epoch [1/5], Step [100/235], Loss: 1.6708\n",
            "Epoch [1/5], Step [150/235], Loss: 0.9210\n",
            "Epoch [2/5], Step [0/235], Loss: 0.6030\n",
            "Epoch [2/5], Step [50/235], Loss: 0.4443\n",
            "Epoch [2/5], Step [100/235], Loss: 0.3744\n",
            "Epoch [2/5], Step [150/235], Loss: 0.3530\n",
            "Epoch [3/5], Step [0/235], Loss: 0.3417\n",
            "Epoch [3/5], Step [50/235], Loss: 0.3363\n",
            "Epoch [3/5], Step [100/235], Loss: 0.3346\n",
            "Epoch [3/5], Step [150/235], Loss: 0.3326\n",
            "Epoch [4/5], Step [0/235], Loss: 0.3298\n",
            "Epoch [4/5], Step [50/235], Loss: 0.3256\n",
            "Epoch [4/5], Step [100/235], Loss: 0.3206\n",
            "Epoch [4/5], Step [150/235], Loss: 0.3162\n",
            "Epoch [5/5], Step [0/235], Loss: 0.3130\n",
            "Epoch [5/5], Step [50/235], Loss: 0.3113\n",
            "Epoch [5/5], Step [100/235], Loss: 0.3103\n",
            "Epoch [5/5], Step [150/235], Loss: 0.3103\n",
            "1\n",
            "Epoch [1/5], Step [0/235], Loss: 25.1431\n",
            "Epoch [1/5], Step [50/235], Loss: 6.3581\n",
            "Epoch [1/5], Step [100/235], Loss: 4.3929\n",
            "Epoch [1/5], Step [150/235], Loss: 3.4431\n",
            "Epoch [2/5], Step [0/235], Loss: 2.9468\n",
            "Epoch [2/5], Step [50/235], Loss: 2.6854\n",
            "Epoch [2/5], Step [100/235], Loss: 2.5221\n",
            "Epoch [2/5], Step [150/235], Loss: 2.4251\n",
            "Epoch [3/5], Step [0/235], Loss: 2.3676\n",
            "Epoch [3/5], Step [50/235], Loss: 2.3310\n",
            "Epoch [3/5], Step [100/235], Loss: 2.3082\n",
            "Epoch [3/5], Step [150/235], Loss: 2.2965\n",
            "Epoch [4/5], Step [0/235], Loss: 2.2885\n",
            "Epoch [4/5], Step [50/235], Loss: 2.2797\n",
            "Epoch [4/5], Step [100/235], Loss: 2.2702\n",
            "Epoch [4/5], Step [150/235], Loss: 2.2629\n",
            "Epoch [5/5], Step [0/235], Loss: 2.2596\n",
            "Epoch [5/5], Step [50/235], Loss: 2.2541\n",
            "Epoch [5/5], Step [100/235], Loss: 2.2458\n",
            "Epoch [5/5], Step [150/235], Loss: 2.2407\n",
            "2\n",
            "Epoch [1/5], Step [0/235], Loss: 13.4347\n",
            "Epoch [1/5], Step [50/235], Loss: 4.8185\n",
            "Epoch [1/5], Step [100/235], Loss: 2.7445\n",
            "Epoch [1/5], Step [150/235], Loss: 2.0243\n",
            "Epoch [2/5], Step [0/235], Loss: 1.7664\n",
            "Epoch [2/5], Step [50/235], Loss: 1.6464\n",
            "Epoch [2/5], Step [100/235], Loss: 1.5887\n",
            "Epoch [2/5], Step [150/235], Loss: 1.5475\n",
            "Epoch [3/5], Step [0/235], Loss: 1.5235\n",
            "Epoch [3/5], Step [50/235], Loss: 1.5078\n",
            "Epoch [3/5], Step [100/235], Loss: 1.5009\n",
            "Epoch [3/5], Step [150/235], Loss: 1.4954\n",
            "Epoch [4/5], Step [0/235], Loss: 1.4887\n",
            "Epoch [4/5], Step [50/235], Loss: 1.4792\n",
            "Epoch [4/5], Step [100/235], Loss: 1.4710\n",
            "Epoch [4/5], Step [150/235], Loss: 1.4666\n",
            "Epoch [5/5], Step [0/235], Loss: 1.4662\n",
            "Epoch [5/5], Step [50/235], Loss: 1.4659\n",
            "Epoch [5/5], Step [100/235], Loss: 1.4662\n",
            "Epoch [5/5], Step [150/235], Loss: 1.4663\n",
            "3\n",
            "Epoch [1/5], Step [0/235], Loss: 9.9865\n",
            "Epoch [1/5], Step [50/235], Loss: 4.2326\n",
            "Epoch [1/5], Step [100/235], Loss: 2.2293\n",
            "Epoch [1/5], Step [150/235], Loss: 1.6672\n",
            "Epoch [2/5], Step [0/235], Loss: 1.4488\n",
            "Epoch [2/5], Step [50/235], Loss: 1.3691\n",
            "Epoch [2/5], Step [100/235], Loss: 1.3357\n",
            "Epoch [2/5], Step [150/235], Loss: 1.3131\n",
            "Epoch [3/5], Step [0/235], Loss: 1.2893\n",
            "Epoch [3/5], Step [50/235], Loss: 1.2758\n",
            "Epoch [3/5], Step [100/235], Loss: 1.2721\n",
            "Epoch [3/5], Step [150/235], Loss: 1.2718\n",
            "Epoch [4/5], Step [0/235], Loss: 1.2701\n",
            "Epoch [4/5], Step [50/235], Loss: 1.2681\n",
            "Epoch [4/5], Step [100/235], Loss: 1.2659\n",
            "Epoch [4/5], Step [150/235], Loss: 1.2627\n",
            "Epoch [5/5], Step [0/235], Loss: 1.2613\n",
            "Epoch [5/5], Step [50/235], Loss: 1.2617\n",
            "Epoch [5/5], Step [100/235], Loss: 1.2620\n",
            "Epoch [5/5], Step [150/235], Loss: 1.2625\n",
            "4\n",
            "Epoch [1/5], Step [0/235], Loss: 24.5466\n",
            "Epoch [1/5], Step [50/235], Loss: 5.8328\n",
            "Epoch [1/5], Step [100/235], Loss: 3.9454\n",
            "Epoch [1/5], Step [150/235], Loss: 3.0935\n",
            "Epoch [2/5], Step [0/235], Loss: 2.6329\n",
            "Epoch [2/5], Step [50/235], Loss: 2.3568\n",
            "Epoch [2/5], Step [100/235], Loss: 2.1829\n",
            "Epoch [2/5], Step [150/235], Loss: 2.0767\n",
            "Epoch [3/5], Step [0/235], Loss: 2.0012\n",
            "Epoch [3/5], Step [50/235], Loss: 1.9573\n",
            "Epoch [3/5], Step [100/235], Loss: 1.9277\n",
            "Epoch [3/5], Step [150/235], Loss: 1.9025\n",
            "Epoch [4/5], Step [0/235], Loss: 1.8827\n",
            "Epoch [4/5], Step [50/235], Loss: 1.8686\n",
            "Epoch [4/5], Step [100/235], Loss: 1.8582\n",
            "Epoch [4/5], Step [150/235], Loss: 1.8526\n",
            "Epoch [5/5], Step [0/235], Loss: 1.8488\n",
            "Epoch [5/5], Step [50/235], Loss: 1.8447\n",
            "Epoch [5/5], Step [100/235], Loss: 1.8412\n",
            "Epoch [5/5], Step [150/235], Loss: 1.8405\n",
            "5\n",
            "Epoch [1/5], Step [0/235], Loss: 13.5733\n",
            "Epoch [1/5], Step [50/235], Loss: 4.9100\n",
            "Epoch [1/5], Step [100/235], Loss: 2.9166\n",
            "Epoch [1/5], Step [150/235], Loss: 2.1897\n",
            "Epoch [2/5], Step [0/235], Loss: 1.8906\n",
            "Epoch [2/5], Step [50/235], Loss: 1.7416\n",
            "Epoch [2/5], Step [100/235], Loss: 1.6639\n",
            "Epoch [2/5], Step [150/235], Loss: 1.6139\n",
            "Epoch [3/5], Step [0/235], Loss: 1.5711\n",
            "Epoch [3/5], Step [50/235], Loss: 1.5279\n",
            "Epoch [3/5], Step [100/235], Loss: 1.4958\n",
            "Epoch [3/5], Step [150/235], Loss: 1.4798\n",
            "Epoch [4/5], Step [0/235], Loss: 1.4734\n",
            "Epoch [4/5], Step [50/235], Loss: 1.4638\n",
            "Epoch [4/5], Step [100/235], Loss: 1.4550\n",
            "Epoch [4/5], Step [150/235], Loss: 1.4538\n",
            "Epoch [5/5], Step [0/235], Loss: 1.4540\n",
            "Epoch [5/5], Step [50/235], Loss: 1.4540\n",
            "Epoch [5/5], Step [100/235], Loss: 1.4543\n",
            "Epoch [5/5], Step [150/235], Loss: 1.4536\n",
            "6\n",
            "Epoch [1/5], Step [0/235], Loss: 20.4026\n",
            "Epoch [1/5], Step [50/235], Loss: 6.1607\n",
            "Epoch [1/5], Step [100/235], Loss: 4.0803\n",
            "Epoch [1/5], Step [150/235], Loss: 3.0581\n",
            "Epoch [2/5], Step [0/235], Loss: 2.5542\n",
            "Epoch [2/5], Step [50/235], Loss: 2.2670\n",
            "Epoch [2/5], Step [100/235], Loss: 2.0964\n",
            "Epoch [2/5], Step [150/235], Loss: 1.9799\n",
            "Epoch [3/5], Step [0/235], Loss: 1.8965\n",
            "Epoch [3/5], Step [50/235], Loss: 1.8461\n",
            "Epoch [3/5], Step [100/235], Loss: 1.8146\n",
            "Epoch [3/5], Step [150/235], Loss: 1.7926\n",
            "Epoch [4/5], Step [0/235], Loss: 1.7754\n",
            "Epoch [4/5], Step [50/235], Loss: 1.7626\n",
            "Epoch [4/5], Step [100/235], Loss: 1.7507\n",
            "Epoch [4/5], Step [150/235], Loss: 1.7477\n",
            "Epoch [5/5], Step [0/235], Loss: 1.7452\n",
            "Epoch [5/5], Step [50/235], Loss: 1.7423\n",
            "Epoch [5/5], Step [100/235], Loss: 1.7400\n",
            "Epoch [5/5], Step [150/235], Loss: 1.7354\n",
            "7\n",
            "Epoch [1/5], Step [0/235], Loss: 22.8405\n",
            "Epoch [1/5], Step [50/235], Loss: 5.8840\n",
            "Epoch [1/5], Step [100/235], Loss: 3.9031\n",
            "Epoch [1/5], Step [150/235], Loss: 2.9162\n",
            "Epoch [2/5], Step [0/235], Loss: 2.4566\n",
            "Epoch [2/5], Step [50/235], Loss: 2.2256\n",
            "Epoch [2/5], Step [100/235], Loss: 2.0745\n",
            "Epoch [2/5], Step [150/235], Loss: 1.9665\n",
            "Epoch [3/5], Step [0/235], Loss: 1.8856\n",
            "Epoch [3/5], Step [50/235], Loss: 1.8326\n",
            "Epoch [3/5], Step [100/235], Loss: 1.8009\n",
            "Epoch [3/5], Step [150/235], Loss: 1.7766\n",
            "Epoch [4/5], Step [0/235], Loss: 1.7615\n",
            "Epoch [4/5], Step [50/235], Loss: 1.7521\n",
            "Epoch [4/5], Step [100/235], Loss: 1.7468\n",
            "Epoch [4/5], Step [150/235], Loss: 1.7430\n",
            "Epoch [5/5], Step [0/235], Loss: 1.7399\n",
            "Epoch [5/5], Step [50/235], Loss: 1.7361\n",
            "Epoch [5/5], Step [100/235], Loss: 1.7309\n",
            "Epoch [5/5], Step [150/235], Loss: 1.7275\n",
            "8\n",
            "Epoch [1/5], Step [0/235], Loss: 9.8627\n",
            "Epoch [1/5], Step [50/235], Loss: 4.1967\n",
            "Epoch [1/5], Step [100/235], Loss: 2.1938\n",
            "Epoch [1/5], Step [150/235], Loss: 1.7042\n",
            "Epoch [2/5], Step [0/235], Loss: 1.4944\n",
            "Epoch [2/5], Step [50/235], Loss: 1.4182\n",
            "Epoch [2/5], Step [100/235], Loss: 1.3821\n",
            "Epoch [2/5], Step [150/235], Loss: 1.3606\n",
            "Epoch [3/5], Step [0/235], Loss: 1.3459\n",
            "Epoch [3/5], Step [50/235], Loss: 1.3376\n",
            "Epoch [3/5], Step [100/235], Loss: 1.3282\n",
            "Epoch [3/5], Step [150/235], Loss: 1.3199\n",
            "Epoch [4/5], Step [0/235], Loss: 1.3159\n",
            "Epoch [4/5], Step [50/235], Loss: 1.3153\n",
            "Epoch [4/5], Step [100/235], Loss: 1.3155\n",
            "Epoch [4/5], Step [150/235], Loss: 1.3151\n",
            "Epoch [5/5], Step [0/235], Loss: 1.3141\n",
            "Epoch [5/5], Step [50/235], Loss: 1.3029\n",
            "Epoch [5/5], Step [100/235], Loss: 1.3030\n",
            "Epoch [5/5], Step [150/235], Loss: 1.3033\n",
            "9\n",
            "Epoch [1/5], Step [0/235], Loss: 15.6671\n",
            "Epoch [1/5], Step [50/235], Loss: 5.2832\n",
            "Epoch [1/5], Step [100/235], Loss: 3.2463\n",
            "Epoch [1/5], Step [150/235], Loss: 2.4210\n",
            "Epoch [2/5], Step [0/235], Loss: 2.0838\n",
            "Epoch [2/5], Step [50/235], Loss: 1.9318\n",
            "Epoch [2/5], Step [100/235], Loss: 1.8595\n",
            "Epoch [2/5], Step [150/235], Loss: 1.8135\n",
            "Epoch [3/5], Step [0/235], Loss: 1.7840\n",
            "Epoch [3/5], Step [50/235], Loss: 1.7475\n",
            "Epoch [3/5], Step [100/235], Loss: 1.7151\n",
            "Epoch [3/5], Step [150/235], Loss: 1.7055\n",
            "Epoch [4/5], Step [0/235], Loss: 1.6993\n",
            "Epoch [4/5], Step [50/235], Loss: 1.6914\n",
            "Epoch [4/5], Step [100/235], Loss: 1.6842\n",
            "Epoch [4/5], Step [150/235], Loss: 1.6785\n",
            "Epoch [5/5], Step [0/235], Loss: 1.6734\n",
            "Epoch [5/5], Step [50/235], Loss: 1.6682\n",
            "Epoch [5/5], Step [100/235], Loss: 1.6671\n",
            "Epoch [5/5], Step [150/235], Loss: 1.6675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(recovered_triggers.detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "cqgUL84KgYr8",
        "outputId": "e89d3b22-5f5c-4a39-da35-be83368b2244"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(recovered_patterns.detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "zkVCyK2MgZBL",
        "outputId": "6feb71e6-67ee-4f3d-ba4e-00bbd2067db3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_images(recovered_masks.detach())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "9LRunsIbgaCD",
        "outputId": "fb291737-7832-4f12-c3e7-de996633b6dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2400x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import sys\n",
        "import time\n",
        "\n",
        "def outlier_detection(l1_norm_list, idx_mapping):\n",
        "    consistency_constant = 1.4826  # if normal distribution\n",
        "    median = np.median(l1_norm_list)\n",
        "    mad = consistency_constant * np.median(np.abs(l1_norm_list - median))\n",
        "    min_mad = np.abs(np.min(l1_norm_list) - median) / mad\n",
        "\n",
        "    print('median: %f, MAD: %f' % (median, mad))\n",
        "    print('anomaly index: %f' % min_mad)\n",
        "\n",
        "    flag_list = []\n",
        "    for y_label in idx_mapping:\n",
        "        if l1_norm_list[idx_mapping[y_label]] > median:\n",
        "            continue\n",
        "        if np.abs(l1_norm_list[idx_mapping[y_label]] - median) / mad > 2:\n",
        "            flag_list.append((y_label, l1_norm_list[idx_mapping[y_label]]))\n",
        "\n",
        "    if len(flag_list) > 0:\n",
        "        flag_list = sorted(flag_list, key=lambda x: x[1])\n",
        "\n",
        "    print('flagged label list: %s' %\n",
        "          ', '.join(['%d: %2f' % (y_label, l_norm)\n",
        "                     for y_label, l_norm in flag_list]))\n",
        "\n",
        "    pass\n",
        "\n",
        "def analyze_pattern_norm_dist(recovered_masks, num_classes):\n",
        "    mask_flatten = []\n",
        "    idx_mapping = {}\n",
        "\n",
        "    for y_label in range(num_classes):\n",
        "        mask = recovered_masks[y_label].cpu().detach().numpy()  # Detach the tensor from the computation graph\n",
        "        mask = mask.squeeze()\n",
        "\n",
        "        mask_flatten.append(mask.flatten())\n",
        "\n",
        "        idx_mapping[y_label] = len(mask_flatten) - 1\n",
        "\n",
        "    l1_norm_list = [np.sum(np.abs(m)) for m in mask_flatten]\n",
        "\n",
        "    print('%d labels found' % len(l1_norm_list))\n",
        "\n",
        "    outlier_detection(l1_norm_list, idx_mapping)\n",
        "\n",
        "    pass\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print('%s start' % sys.argv[0])\n",
        "\n",
        "    num_classes = 10\n",
        "\n",
        "    start_time = time.time()\n",
        "    analyze_pattern_norm_dist(recovered_masks, num_classes)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print('elapsed time %.2f s' % elapsed_time)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ujnUasKVga0O",
        "outputId": "e1c08c8c-1346-47b4-8b19-5908f2abf255"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/ipykernel_launcher.py start\n",
            "10 labels found\n",
            "median: 69.771179, MAD: 37.420049\n",
            "anomaly index: 0.759759\n",
            "flagged label list: \n",
            "elapsed time 0.00 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "for each optimzer accumulate the data into bathc\n",
        "after\n",
        "\"\"\"\n",
        "\n",
        "#pytooch optimizer\n",
        "optimizer = torch.optim.SGD(lr=args.lr)\n",
        "\n",
        "\n",
        "#batch of data from train_dataset using dataloader\n",
        "for batch in Dataloader(train_dataset, batch_size=32):\n",
        "    #input data x corresponding target data y for each batch\n",
        "    x, y = batch\n",
        "    #for each predict output y_hat given the input x\n",
        "    y_hat = model(x)\n",
        "\n",
        "    #calcaulates the loss between the predicted output \"y_hat\" and the target labels \"y\"\n",
        "    loss = criterion(y_hat, y)\n",
        "    #backpropahated through the model using loss.backward()\n",
        "    loss.backward()\n",
        "    \n",
        "    # the differential privacy mechanism is applied \"generator expression gradients\" \n",
        "    gradients = (p.grad for p in model.parameters())\n",
        "    #p in model's parametwers add random noise \"distribution with mean 0 standard devation\"\n",
        "    for p in model.parameters():\n",
        "\n",
        "        # Add our differential privacy magic here\n",
        "        p.grad += torch.normal(mean=0, std=args.sigma)\n",
        "        \n",
        "        # This is what optimizer.step() does\n",
        "        #args.lr: learning rate\n",
        "        #p.grad:corresponds to the gradient of the parameter\n",
        "        #args.lr * p.grad :learning rate and direction \n",
        "        p = p - args.lr * p.grad\n",
        "        p.grad.zero_()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "mnqteUENRIV1",
        "outputId": "bf28d8c9-01ba-47ed-f687-3438929a66f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-567d77af31fd>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    \"\"\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#SGD optimzier \n",
        "optimizer = torch.optim.SGD(lr=args.lr)\n",
        "#for each batch into dataloader size 32\n",
        "for batch in Dataloader(train_dataset, batch_size=32):\n",
        "    all_per_sample_gradients = [] # will have len = batch_size\n",
        "    #for each batch  \n",
        "    for sample in batch:\n",
        "        #x input data combined with y label \n",
        "        x, y = sample\n",
        "        #y_hat as predict output for input x\n",
        "        y_hat = model(x)\n",
        "        #loss functio  calculate the difference between predict t_hat and the true label y\n",
        "        loss = criterion(y_hat, y)\n",
        "        #pytorch function of loss is bacjpropagated \n",
        "        loss.backward()  # Now p.grad for this x is filled\n",
        "        \n",
        "        #create list of contains the graidents for each paramter \n",
        "        #detach method use to detach the gradient tensors from the computation\n",
        "        #clone used to cteate the copy of the detached gradients \n",
        "        per_sample_gradients = [p.grad.detach().clone() for p in model.parameters()]\n",
        "        \n",
        "        #collecting the gradients for each sample\n",
        "        all_per_sample_gradients.append(per_sample_gradients)\n",
        "        model.zero_grad()  # p.grad is cumulative so we'd better reset it"
      ],
      "metadata": {
        "id": "okkv0QU0ZPcL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torch.nn.utils import clip_grad_norm_\n",
        "#is used to clip gradients to prevent them from exploding during trainning \n",
        "\n",
        "#optmizer SGD with learning rate = arg.lr(commmonly used for trainning deep learning model)\n",
        "optimizer = torch.optim.SGD(lr=args.lr)\n",
        "\n",
        "for batch in Dataloader(train_dataset, batch_size=32):\n",
        "    for param in model.parameters():\n",
        "        param.accumulated_grads = []\n",
        "    \n",
        "    # Run the microbatches\n",
        "    for sample in batch:\n",
        "        x, y = sample\n",
        "        y_hat = model(x)\n",
        "        loss = criterion(y_hat, y)\n",
        "        loss.backward()\n",
        "    \n",
        "        # Clip each parameter's per-sample gradient\n",
        "        for param in model.parameters():\n",
        "            per_sample_grad = p.grad.detach().clone()\n",
        "            clip_grad_norm_(per_sample_grad, max_norm=args.max_grad_norm)  # in-place\n",
        "            param.accumulated_grads.append(per_sample_grad)  \n",
        "        \n",
        "    # Aggregate back\n",
        "    for param in model.parameters():\n",
        "        param.grad = torch.stack(param.accumulated_grads, dim=0)\n",
        "\n",
        "    # Now we are ready to update and add noise!\n",
        "    for param in model.parameters():\n",
        "        param = param - args.lr * param.grad\n",
        "        param += torch.normal(mean=0, std=args.noise_multiplier * args.max_grad_norm)"
      ],
      "metadata": {
        "id": "FRMGtohfcLam"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "IX1HocbIW1yP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}